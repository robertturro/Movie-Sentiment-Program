{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>grew b NUMBER watching loving thunderbird mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         clean_text\n",
       "0      0  grew b NUMBER watching loving thunderbird mate...\n",
       "1      0  put movie dvd player sat coke chip expectation...\n",
       "2      0  people know particular time past like feel nee...\n",
       "3      0  even though great interest biblical movie bore...\n",
       "4      1  im die hard dad army fan nothing ever change g..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('movie_reviews.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1</td>\n",
       "      <td>western union something forgotten classic west...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1</td>\n",
       "      <td>movie incredible piece work explores every noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0</td>\n",
       "      <td>wife watched movie plan visit sicily stromboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1</td>\n",
       "      <td>first watched flatliners amazed necessary feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1</td>\n",
       "      <td>would film good gross estimated NUMBER award n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                         clean_text\n",
       "39995      1  western union something forgotten classic west...\n",
       "39996      1  movie incredible piece work explores every noo...\n",
       "39997      0  wife watched movie plan visit sicily stromboli...\n",
       "39998      1  first watched flatliners amazed necessary feat...\n",
       "39999      1  would film good gross estimated NUMBER award n..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew b NUMBER watching loving thunderbird mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text\n",
       "0  grew b NUMBER watching loving thunderbird mate...\n",
       "1  put movie dvd player sat coke chip expectation...\n",
       "2  people know particular time past like feel nee...\n",
       "3  even though great interest biblical movie bore...\n",
       "4  im die hard dad army fan nothing ever change g..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train['clean_text'].tolist()\n",
    "\n",
    "labels = y_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [str(i) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9330\n"
     ]
    }
   ],
   "source": [
    "ma = 0\n",
    "for i in sentences:\n",
    "    if len(i)>ma:\n",
    "        ma = len(i) \n",
    "        \n",
    "print(ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = 50000\n",
    "oov = '<OOV>'\n",
    "embedding = 500\n",
    "padding = 'post'\n",
    "truncate = 'post'\n",
    "maxlength = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8*len(sentences)\n",
    "ratio = int(ratio)\n",
    "# print(ratio)\n",
    "train = sentences[0:ratio]\n",
    "train_label = labels[0:ratio]\n",
    "val = sentences[ratio:]\n",
    "val_labels = labels[ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =Tokenizer(num_words = vocab, oov_token=oov)\n",
    "tokenizer.fit_on_texts(train)\n",
    "word_index = tokenizer.word_index\n",
    "training = tokenizer.texts_to_sequences(train)\n",
    "training_pad = pad_sequences(training, maxlen=maxlength, padding=padding, truncating=truncate)\n",
    "\n",
    "validation = tokenizer.texts_to_sequences(val)\n",
    "validation_pad = pad_sequences(validation, maxlen=maxlength, padding=padding, truncating=truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5000, 500)         25000000  \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 500)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               150300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               45150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,195,601\n",
      "Trainable params: 25,195,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab, embedding, input_length=maxlength),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(300,activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(150, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adamax',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.array(val_labels)\n",
    "train_label = np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 277s 276ms/step - loss: 0.6967 - accuracy: 0.4987 - val_loss: 0.6948 - val_accuracy: 0.4983\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 277s 277ms/step - loss: 0.6945 - accuracy: 0.5097 - val_loss: 0.6960 - val_accuracy: 0.5017\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 277s 277ms/step - loss: 0.6773 - accuracy: 0.5769 - val_loss: 0.6431 - val_accuracy: 0.7028\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 274s 274ms/step - loss: 0.5585 - accuracy: 0.7566 - val_loss: 0.4680 - val_accuracy: 0.8195\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 271s 271ms/step - loss: 0.4280 - accuracy: 0.8177 - val_loss: 0.3946 - val_accuracy: 0.8384\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 272s 272ms/step - loss: 0.3772 - accuracy: 0.8396 - val_loss: 0.3586 - val_accuracy: 0.8596\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 275s 275ms/step - loss: 0.3494 - accuracy: 0.8530 - val_loss: 0.3919 - val_accuracy: 0.8215\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 275s 275ms/step - loss: 0.3267 - accuracy: 0.8632 - val_loss: 0.3437 - val_accuracy: 0.8558\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 272s 272ms/step - loss: 0.3105 - accuracy: 0.8721 - val_loss: 0.3612 - val_accuracy: 0.8422\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 271s 271ms/step - loss: 0.3016 - accuracy: 0.8757 - val_loss: 0.3079 - val_accuracy: 0.8796\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 274s 274ms/step - loss: 0.2911 - accuracy: 0.8802 - val_loss: 0.3081 - val_accuracy: 0.8763\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 278s 278ms/step - loss: 0.2856 - accuracy: 0.8833 - val_loss: 0.3014 - val_accuracy: 0.8800\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 278s 278ms/step - loss: 0.2725 - accuracy: 0.8903 - val_loss: 0.3046 - val_accuracy: 0.8796\n",
      "Epoch 14/25\n",
      "1000/1000 [==============================] - 275s 275ms/step - loss: 0.2702 - accuracy: 0.8900 - val_loss: 0.4116 - val_accuracy: 0.8198\n",
      "Epoch 15/25\n",
      "1000/1000 [==============================] - 278s 278ms/step - loss: 0.2612 - accuracy: 0.8930 - val_loss: 0.3147 - val_accuracy: 0.8709\n",
      "Epoch 16/25\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.2558 - accuracy: 0.8972 - val_loss: 0.2918 - val_accuracy: 0.8881\n",
      "Epoch 17/25\n",
      "1000/1000 [==============================] - 275s 275ms/step - loss: 0.2524 - accuracy: 0.8977 - val_loss: 0.2886 - val_accuracy: 0.8864\n",
      "Epoch 18/25\n",
      "1000/1000 [==============================] - 276s 276ms/step - loss: 0.2471 - accuracy: 0.9004 - val_loss: 0.2924 - val_accuracy: 0.8861\n",
      "Epoch 19/25\n",
      "1000/1000 [==============================] - 278s 278ms/step - loss: 0.2409 - accuracy: 0.9014 - val_loss: 0.3541 - val_accuracy: 0.8535\n",
      "Epoch 20/25\n",
      "1000/1000 [==============================] - 270s 270ms/step - loss: 0.2361 - accuracy: 0.9053 - val_loss: 0.2855 - val_accuracy: 0.8890\n",
      "Epoch 21/25\n",
      "1000/1000 [==============================] - 270s 270ms/step - loss: 0.2318 - accuracy: 0.9083 - val_loss: 0.2833 - val_accuracy: 0.8905\n",
      "Epoch 22/25\n",
      "1000/1000 [==============================] - 272s 272ms/step - loss: 0.2302 - accuracy: 0.9084 - val_loss: 0.2887 - val_accuracy: 0.8856\n",
      "Epoch 23/25\n",
      "1000/1000 [==============================] - 274s 274ms/step - loss: 0.2284 - accuracy: 0.9079 - val_loss: 0.2930 - val_accuracy: 0.8855\n",
      "Epoch 24/25\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.2184 - accuracy: 0.9121 - val_loss: 0.2828 - val_accuracy: 0.8899\n",
      "Epoch 25/25\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.2198 - accuracy: 0.9130 - val_loss: 0.3065 - val_accuracy: 0.8783\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "history = model.fit(training_pad, \n",
    "                    train_label, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_data=(validation_pad, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\robtu\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\robtu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
